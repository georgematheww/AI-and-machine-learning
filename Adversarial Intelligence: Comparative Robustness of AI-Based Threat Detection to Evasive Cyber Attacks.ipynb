{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0Q6I14+ZMPyUS+iht/m1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgematheww/AI-and-machine-learning/blob/main/Adversarial%20Intelligence%3A%20Comparative%20Robustness%20of%20AI-Based%20Threat%20Detection%20to%20Evasive%20Cyber%20Attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXUvf_sOlhSp",
        "outputId": "462d4565-5bcd-4248-e6f3-331507913025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Downloading NSL-KDD Dataset...\n",
            "--2025-12-04 22:58:35--  https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19109424 (18M) [text/plain]\n",
            "Saving to: ‘KDDTrain.txt’\n",
            "\n",
            "KDDTrain.txt        100%[===================>]  18.22M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-04 22:58:36 (402 MB/s) - ‘KDDTrain.txt’ saved [19109424/19109424]\n",
            "\n",
            "--2025-12-04 22:58:36--  https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3441513 (3.3M) [text/plain]\n",
            "Saving to: ‘KDDTest.txt’\n",
            "\n",
            "KDDTest.txt         100%[===================>]   3.28M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-12-04 22:58:36 (275 MB/s) - ‘KDDTest.txt’ saved [3441513/3441513]\n",
            "\n",
            ">>> Preprocessing Data...\n",
            "    Train Shape: (125973, 38)\n",
            "    Test Shape:  (22544, 38)\n",
            "\n",
            ">>> Training SVM (This may take ~60 seconds)...\n",
            "    SVM Clean Accuracy: 74.75%\n",
            "\n",
            ">>> Training CNN...\n",
            "Epoch 1/3\n",
            "\u001b[1m3543/3543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1365 - val_accuracy: 0.9744 - val_loss: 0.0669\n",
            "Epoch 2/3\n",
            "\u001b[1m3543/3543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0643 - val_accuracy: 0.9806 - val_loss: 0.0499\n",
            "Epoch 3/3\n",
            "\u001b[1m3543/3543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0509 - val_accuracy: 0.9839 - val_loss: 0.0432\n",
            "    CNN Clean Accuracy: 77.84%\n",
            "\n",
            ">>> Generating FGSM Attacks...\n",
            "\n",
            "==================================================\n",
            "FINAL RESULTS: ROBUSTNESS GAP ANALYSIS\n",
            "==================================================\n",
            "1. SVM Clean Accuracy:       74.75%\n",
            "2. CNN Clean Accuracy:       77.84%\n",
            "3. CNN Adversarial Accuracy: 25.90% (Under FGSM Attack)\n",
            "--------------------------------------------------\n",
            "ROBUSTNESS GAP: 51.94 percentage points\n",
            "==================================================\n",
            "CONCLUSION: The CNN collapsed under attack (High Gap).\n",
            "This confirms the 'Glass Cannon' theory from the abstract.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# FULL MINI-SCALE REPLICATION: CNN vs SVM Robustness\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. INSTALL LIBRARIES\n",
        "# ------------------------------------------------------------------------------\n",
        "!pip install tensorflow scikit-learn pandas numpy matplotlib -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Input\n",
        "\n",
        "# 2. DATA LOADING & PREPROCESSING\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\">>> Downloading NSL-KDD Dataset...\")\n",
        "!wget https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt -O KDDTrain.txt\n",
        "!wget https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt -O KDDTest.txt\n",
        "\n",
        "cols = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"class\",\"difficulty\"]\n",
        "\n",
        "# Load CSVs\n",
        "df_train = pd.read_csv('KDDTrain.txt', names=cols)\n",
        "df_test = pd.read_csv('KDDTest.txt', names=cols)\n",
        "\n",
        "def preprocess_mini_scale(df):\n",
        "    \"\"\"\n",
        "    Simplified preprocessing for the mini-scale test:\n",
        "    1. Maps 'normal' to 0 and attacks to 1.\n",
        "    2. Drops categorical text columns to avoid complex encoding steps.\n",
        "    \"\"\"\n",
        "\n",
        "    df['label'] = df['class'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "\n",
        "\n",
        "    df = df.drop(['protocol_type', 'service', 'flag', 'class', 'difficulty'], axis=1)\n",
        "    return df\n",
        "\n",
        "print(\">>> Preprocessing Data...\")\n",
        "df_train = preprocess_mini_scale(df_train)\n",
        "df_test = preprocess_mini_scale(df_test)\n",
        "\n",
        "# Extract X (features) and y (labels)\n",
        "X_train = df_train.drop('label', axis=1).values\n",
        "y_train = df_train['label'].values\n",
        "X_test = df_test.drop('label', axis=1).values\n",
        "y_test = df_test['label'].values\n",
        "\n",
        "# Scale Data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for CNN (Samples, Features, 1)\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "print(f\"    Train Shape: {X_train.shape}\")\n",
        "print(f\"    Test Shape:  {X_test.shape}\")\n",
        "\n",
        "# 3. BUILD & TRAIN MODELS\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# --- A. SVM (The \"Robust\" Baseline) ---\n",
        "print(\"\\n>>> Training SVM (This may take ~60 seconds)...\")\n",
        "\n",
        "svm = SVC(kernel='rbf', C=1.0)\n",
        "svm.fit(X_train[:10000], y_train[:10000])\n",
        "svm_acc = svm.score(X_test, y_test)\n",
        "print(f\"    SVM Clean Accuracy: {svm_acc * 100:.2f}%\")\n",
        "\n",
        "# --- B. CNN (The \"Glass Cannon\") ---\n",
        "print(\"\\n>>> Training CNN...\")\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1], 1)),       # Explicit Input Layer\n",
        "    Conv1D(32, 3, activation='relu'),         # Convolution\n",
        "    MaxPooling1D(2),                          # Pooling\n",
        "    Flatten(),                                # Flatten to 1D\n",
        "    Dense(64, activation='relu'),             # Dense Layer\n",
        "    Dense(1, activation='sigmoid')            # Output (Binary)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_cnn, y_train, epochs=3, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluate on clean data\n",
        "loss, cnn_clean_acc = model.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(f\"    CNN Clean Accuracy: {cnn_clean_acc * 100:.2f}%\")\n",
        "\n",
        "# 4. ADVERSARIAL ATTACK (FGSM)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n>>> Generating FGSM Attacks...\")\n",
        "\n",
        "def fgsm_attack_safe(model, images, labels, epsilon=0.1):\n",
        "    \"\"\"\n",
        "    Generates Adversarial Examples using Fast Gradient Sign Method.\n",
        "    FIXED: Explicitly handles Tensor/Numpy conversion for Keras 3 compatibility.\n",
        "    \"\"\"\n",
        "    # 1. Convert to constant Tensors for the calculation\n",
        "    images_tensor = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "    labels_tensor = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(images_tensor)\n",
        "        predictions = model(images_tensor)\n",
        "        loss = tf.keras.losses.binary_crossentropy(labels_tensor, predictions)\n",
        "\n",
        "    # 2. Calculate Gradient\n",
        "    gradient = tape.gradient(loss, images_tensor)\n",
        "\n",
        "    # 3. Create Perturbation (Sign of Gradient)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "\n",
        "    # 4. Apply Noise\n",
        "    adversarial_images = images_tensor + (epsilon * signed_grad)\n",
        "\n",
        "    return adversarial_images.numpy()\n",
        "\n",
        "# Attack Parameters\n",
        "epsilon = 0.1\n",
        "sample_size = 1000\n",
        "\n",
        "# Prepare sample data\n",
        "X_sample = X_test_cnn[:sample_size]\n",
        "y_sample = y_test[:sample_size].reshape(-1, 1).astype(np.float32)\n",
        "\n",
        "# Generate the attack\n",
        "X_adv = fgsm_attack_safe(model, X_sample, y_sample, epsilon=epsilon)\n",
        "\n",
        "# Evaluate the CNN on the attacked data\n",
        "loss_adv, cnn_adv_acc = model.evaluate(X_adv, y_sample, verbose=0)\n",
        "\n",
        "# 5. FINAL REPORT (JOINT DISPLAY)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL RESULTS: ROBUSTNESS GAP ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"1. SVM Clean Accuracy:       {svm_acc * 100:.2f}%\")\n",
        "print(f\"2. CNN Clean Accuracy:       {cnn_clean_acc * 100:.2f}%\")\n",
        "print(f\"3. CNN Adversarial Accuracy: {cnn_adv_acc * 100:.2f}% (Under FGSM Attack)\")\n",
        "print(\"-\" * 50)\n",
        "gap = (cnn_clean_acc * 100) - (cnn_adv_acc * 100)\n",
        "print(f\"ROBUSTNESS GAP: {gap:.2f} percentage points\")\n",
        "print(\"=\"*50)\n",
        "if gap > 20:\n",
        "    print(\"CONCLUSION: The CNN collapsed under attack (High Gap).\")\n",
        "    print(\"This confirms the 'Glass Cannon' theory from the abstract.\")\n",
        "else:\n",
        "    print(\"CONCLUSION: The CNN resisted the attack.\")"
      ]
    }
  ]
}